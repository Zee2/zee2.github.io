---
layout: page
title: "Building Volumetric UI in MRTK3"
---

MRTK3 represents a significant step forward in the maturity of our user interface design tooling in MRTK. Over the last year (and more) we've invested significant resources into modernizing our design systems for UI in mixed reality, as well as overhauling the component libraries and tooling for building out these UI designs in Unity. If you've had experience with MRTK in the past, you'll know that building beautiful, modern user interfaces for mixed reality applications has never been an easy task. High-quality volumetric UI requires unique tools and systems, and organizing all of it under a cohesive design language is even harder.

In the course of developing more mature design systems, we've run into and overcome several categories of UI tooling challenges with our existing setup, ranging from the human challenges (usability, workflow, keeping a large design team consistent) to the engineering challenges (layout engines, 3D volumetric interactions, analog input, rendering/shaders).

In the next generation of UI tooling for MRTK3, we've sought to significantly improve the developer experience with more powerful engineering systems, improve the designer experience with more modern design features, and improve the user experience with more delightful, immersive, and "delicious" microinteractions and design language.

<video loop autoplay muted src="/images/canvas/spinning.mp4"></video>

## Variant Explosion

In previous versions of MRTK, designing 3D UI often meant manual calculations, back-of-the-napkin math for alignments and padding, and a lot of hand-placed assets that couldn't respond to changes in layout or dimensions. Most of these limitations were due to the fact that the main way of building UI in MRTK2 didn't use the typical UI tooling available in Unity. Later versions of MRTK2 explored building 3D UI with Canvas and RectTransform layouts, but it was never the preferred/primary way to build UI in MRTK.

Internally at Microsoft, as we've built bigger and more ambitious applications for MR devices, we've hit the scale where we need more modern design tooling, workflows, and methods for managing highly complex UI layouts. When you have 100+ engineers, designers, and PMs, keeping design language and layouts consistent is a significant challenge! If we were still using the manual methods of aligning, sizing, and designing UI, we'd quickly hit a wall of hundreds of slightly misaligned buttons, off-by-a-millimeter issues, exponentially exploding numbers of prefab variants and assets... a true nightmare.

![Image showing how many permutations of buttons there used to be!](/images/canvas/Prefabs.png)

External customers of MRTK in the past might have experienced miniature versions of this problem in the past, notably from the huge number of prefabs and prefab variants required to describe all possible configurations and sizes of UI controls. We had an exponentially-nasty number of variants, where we required variants for every permutation of button style, configuration, layout, and even *size*! (That last one was particularly frustrating...)

With MRTK3, we've drastically reduced the number of prefabs. Instead of needing prefab variants for sizes and configurations, we can use a single prefab and allow the user to freely resize the controls, add and remove their own sub-features within the control, and even expand button groups/lists/menus with dynamic layout.

![New UI](/images/canvas/new_ui.png)

(Nearly) every button you generally work with in MRTK3 will be the same prefab. All UI elements are resizable and can be dynamically fit both to their surrounding containers and to the content they wrap. None of this is really an MRTK-specific invention; we're just ensuring that all of our UX is built to the same standards that Unity's own UI is built, with compatibility for all of the existing layout groups, constraints, and alignement systems.

<img src="/images/canvas/layout_demo.gif" width=275/>

Every single button you see on this UI tearsheet is actually, in fact, the exact same prefab:

![Tearsheet](/images/canvas/tearsheet.png)

The speed at which designers can build UI templates is drastically accelerated. It's actually *fun*, now, to build UI in MRTK... simple building blocks, combined together, to form more complex layouts.

## Measurements

Another problem with working with UI at scale is that there are very specific requirements from the design language/library for measurements, both for usability concerns (minimum touch targets, readability, etc) as well as design (padding, margin, corner radii, branding). This was one of the most critical areas where our design in mixed reality had departed from the typical workflow that most designers are used to in 2D contexts. In the past, we had not only specified everything in absolute coordinates without any sort of flex or alignment parameters, but we used physical, real-world units for *everything*. All UI was designed in millimeters; branding guidelines were in millimeters, margin, padding, gutter, spacing, all in millimeters. Even fonts were specified in millimeters!

This had some advantages: notably, we were working in a real, physical environment. UI in mixed reality isn't just some abstract piece of information on a screen somewhere; it's essentially a real, physical object that exists in the real, physical world! It must have a defined physical size with physical units, at some point in the development process. We also have very strict requirements for usability with holograms; we have user research telling us that certain touch target sizes (32mm x 32mm, or 24mm at the absolute smallest) is acceptable for performing 3D volumetric pressing interactions with our fingers.

However, this attachment to physical units also had drawbacks. Primarily, this is an alien working environment to typical front-end designers, who are used to non-physical design units like `em`, `rem`, `%`, `vh`, or "physical" units that aren't even really *phsyical* to begin with (`px`, `pt`). Traditional 2D design has a concept of DPI, or screen density, as well; but in mixed reality, there's a much closer relationship between design and the physical world. (I like to think about it as something closer to industrial design, or physical product design: you're building real, physical affordances that sit on a real, physical object!)

The most direct drawback was that in this system of everything being specified in absolute physical units, there was zero room at all for *scaling*. In mixed reality, there are still some circustances where the entire UI layout or design should be scaled up or down; this is common when reusing UI layouts for faraway, large objects (or reusing UI layouts for near or far interaction!) For UI elements like stroke, outline, and corner radius, we use shader-driven rendering techniques. When these are specified only in absolute physical units (like, say, a "1mm" stroke, or a "5mm" corner radius), there is no way for these measurements to remain *proportionally consistent* with the rest of your design. If your 32mm x 32mm button is scaled up 5x, your 1mm and 5mm design elements will still remain 1mm thick and 5mm wide. They will be *proportionally* incorrect, despite being specified in *absolute* units.

This gets pretty confusing, but the core of the issue is this: without RectTransforms or Canvas, there is no such thing as a *dimension*. There is only *scale*. For elements like stroke, or corner radius, we had to specify them "absolutely" so that they were consistent across the *scaling* operations used to adjust their size and shape. However, when the overall UI layout needed to be scaled up or down, those absolute measurements would become proportionally incorrect.

Here, let's take a look at some visual examples to make this a bit less confusing. First, let's see what happens to a non-RectTransform-based Dialog control when we want to "scale it up":

![Scaling a non-Canvas element](/images/canvas/scaledemo.png)

If your corner radius is specified to be exactly 5mm, what happens if you'd like to *scale* the entire design up or down? If these physical units are taken at face value, then **all of your design elements and branding will be distorted**, relative to your content. Your corner radius really isn't 5 millimeters, absolutely: it ought to be the *equivalent* of 5mm when the rest of your touch targets, content, etc is measured in a 1:1 millimeter scale. The same problems apply to other measurements for elements like strokes, outlines, paddings, and essentially any other UI element that isn't a piece of physical geometry scaled by the Unity transforms themeslves.

Let's look at some real examples. Here's what it would look like if you wanted to take a design specified in absolute physical units for stroke and corner radius, and scaled it up.

